### 简介
RDD全称为`Resilient Distributed Dataset`，为**内存**里的数据抽象模型，适合需要共享中间结果的计算模型：迭代计算、交互式数据分析。基于RDD实现的计算框架称为Spark。

主要特点有两个：只读(read-only, immutable)、只支持粗粒度(coarse-grained)的操作。

所谓的粗粒度是指：相对于传统的DSM(分布式内存)来说，RDD不支持数据的随机(任意位置)更新，任何操作都是针对RDD上所有数据记录(record)的。

RDD是对数据的抽象，不能凭空创建，必须派生自原始数据(如HDFS上数据块)或其他RDD，RDD一旦生成就不能修改，只能基于当前RDD生成别的RDD(数量不定)，每个RDD的来龙去脉都会被记录下来，这种RDD的派生轨迹信息称为lineage，主要记录是针对RDD的操作(transformation)。

lineage用于某个数据块丢失后的恢复，相对于基于复制的数据备份/恢复机制来说，lineage方法不需要跨网络传输大量的数据，因此数据恢复速度更快。

### 编程接口
Spark通过Scala将数据集与针对数据的操作封装成RDD，Scala是一种静态类型的函数式编程语言，Spark采用它主要是因为Scala简洁高效(不是因为它是函数式编程语言)，RDD本身是有类型的，如`RDD[int]`代表整型数据集。模型框架如下图所示：

<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/4_parallel_processing/imgs/rdd_driver.png"/>

RDD由图中的`Driver`定义，并由其负责记录RDD的派生轨迹(lineage)，针对RDD的操作由后面的worker负责执行。

针对RDD的操作已经封装好了，分为两种：`transformation`、`action`。transformation是一种懒操作，只是说明了RDD的派生轨迹，并不会真的给派生出的RDD填充数据；action则会按照要求将数据填充到RDD中，然后返回给用户或写到外部存储介质中。

transformation包括map、filter、join、reducebykey等；action包括count、collect、reduce等。

### 依赖关系
为了更好的记录RDD派生轨迹(lineage)信息，每个RDD都包含5个相关接口来展示相关的元数据信息：数据分片、依赖信息、操作函数、分片规则(schema)、数据存放位置等。

根据产生子RDD的数量可以将依赖关系分为两种：宽依赖、窄依赖。

窄依赖：父RDD中分片(partition)至多被一个子RDD中的partition使用(依赖)，注意，一个子RDD中的partition可能同时使用(依赖)多个父RDD的partition。如下图所示：

<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/4_parallel_processing/imgs/rdd_narrow.png"/>

宽依赖：父RDD中分片被不只一个子RDD中的分片所使用，如下图所示：

<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/4_parallel_processing/imgs/rdd_wide.png"/>

在调用action相关操作时，spark会构造一个以`stage`为节点的DAG图，stage的划分以宽依赖或已存在的partition为边界，如下图所示：

<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/4_parallel_processing/imgs/rdd_stage.png"/>


### 性能评测
- 针对迭代式的机器学习算法/图计算应用，Spark比Haddop快20多倍，速度的提升主要得益于数据在内存中读写，且不需要做序列化/反序列化操作

- 同一个应用在spark上比在handoop快40多倍

- 当某个节点掉线后，数据可以快速恢复

- 遍历1TB的数据只需要5～7秒

- 表达能力(普适性)很强：很多其他计算框架支持的模型都能在spark里实现
