### 简介
传统的分布式存储系统(如GFS)为了保证可用性，会把同一份数据在不同的地方存放多份，这样不但拖慢了数据写入速度，而且也浪费了很多网络带宽，针对这个问题本文通过lineage技术实现了一个基于内存的分布式数据共享系统：**Tachyon**(现已改名为`Alluxio`)。当出现数据丢失时，lineage可以基于之前所做的checkpoint进行回放(`recomputation`)来恢复数据，这一过程不需要其他节点上有备份数据，因此加快了数据恢复速度，而且节省了很多计算资源。

应用tachyon需要满足以下几个前提条件：
- 数据一旦就不再修改
- 任务是确定的(deterministic)
- 基于数据的存放位置进行调度
- 当前任务所处理的数据能够全部加载到内存(不是全部数据，是当前处理所涉及到的数据)
- 任务程序不能太大：程序可能需要在不同的节点上反复运行，程序迁移代价不能大于数据的迁移代价


### 工作流程说明
<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/2_storage/imgs/tachyon_flow.png"/>

假定任务`P`的输入文件集为`A`，输出文件集为`B`，P在把结果输出到B之前，需要先把lineage信息提交到tachyon里，这些信息描述如何运行`P`来由`A`产生`B`(比如命令行参数、配置信息等)。在这里能够回放(recomputation)的前提是输入数据(文件集`A`)不能变。

从以上流程可以看出，tachyon需要捕获并理解用户提交的任务`P`：tachyon内置了通用了的lineage API(见下表)可以捕获很多流行的分布式并行处理的框架(如mapreduce)，同时也为Spark/Hadoop提供了接口。

| Return | Signature |
| ------ | ------ |
| Global Unique Lineage Id | createDependency(inputFiles, outputFiles, binaryPrograms, executionConfiguration, dependencyType) |
| Dependency Info | getDependency(lineageId) |

`createDependency`中的参数`binaryPrograms`即为上文提到的任务程序`P`，这个程序需要由计算框架来写一个wrapper作为接口，使其既能理解框架里计算代码，也能理解tachyon的行为，tachyon也不会去解析程序的配置信息`executionConfiguration`，在tachyon看来这些配置就是普通的字节数组，具体的解析工作由wrapper来实现。

在实现这一系统时，遇到了两个挑战：
- 如何在长时间运行的系统上限制recomputation的时长(bounding the recomputation cost)
- 如何为recomputation分配资源？(如何在尽量不对其他任务产生影响的情况下尽快的执行recomputation)


### Bounding the recomputation cost（Edge Algorithm）
lineage本质上还是一个基于checkpoint做数据备份与恢复的技术，这里的关键点是何时做checkpoint，针对哪些文件做checkpoint？
- 在一个长时间运行的系统上，如果checkpoint的时机选择不好，lineage的链会很长，recomputation的时间也会很长
- 有些文件的访问频率要远高于其他文件，这类文件(热点文件)也应该被checkpoint
- 尽量避免checkpoint临时文件：Facebook给出的数据表明，超过70%的数据会在一天之内被删除，这类文件都不应该被checkpoint

基于以上考虑本文提出了Edge算法：将工作流中各个计算任务的输入/输出文件抽象程DAG(有向无环图)，其顶点是文件集，边表示依赖关系：如果文件集A是某个任务的输入，文件集B是其输出，则有一条由A指向B的有向边将二者连接起来。为了限制recomputation的时间，Edge算法会checkpoint这个DAG的所有边缘节点，除此之外，Edge算法还会checkpoint DAG内部的热点文件(访问次数超过2次的文件)。

Tachyon是一个基于内存的存储系统，大部分的I/O都在内存，tachyon采用上述Edge算法`异步`地将内存中的数据checkpoint到硬盘上。


### Resource allocation for recomputation
资源分配所需要考虑的问题包括：
- 支持优先级：recomputation的优先级应该与原任务相当，如果某个低优先级请求的数据丢了，需要回放，那么这个回放任务不应该对高优先级的任务产生影响，但后来这个文件又被某个高优先级的任务请求了，那么这个回放任务的优先级应该提高
- 资源动态分配：不应该为recomputation预留资源，需要recomputation的时候才为其分配资源
- 避免级联recomputation：针对这种A-->B-->C-->A带有循环依赖的情况，应该避免无穷递归recomputation




### 系统架构