### 简介
传统的分布式存储系统(如GFS)为了保证可用性，会把同一份数据在不同的地方存放多份，这样不但拖慢了数据写入速度，而且也浪费了很多网络带宽，针对这个问题本文通过lineage技术实现了一个基于内存的分布式数据共享系统：**Tachyon**(现已改名为`Alluxio`)。当出现数据丢失时，lineage可以基于之前所做的checkpoint进行回放(`recomputation`)来恢复数据，这一过程不需要其他节点上有备份数据，因此加快了数据恢复速度，而且节省了很多计算资源。

应用tachyon需要满足以下几个前提条件：
- 数据一旦就不再修改
- 任务是确定的(deterministic)
- 基于数据的存放位置进行调度
- 当前任务所处理的数据能够全部加载到内存(不是全部数据，是当前处理所涉及到的数据)
- 任务程序不能太大：程序可能需要在不同的节点上反复运行，程序迁移代价不能大于数据的迁移代价

### 工作流程说明
<img src="https://github.com/zxhcodes/distributed-computing-course/blob/master/2_storage/imgs/tachyon_flow.png"/>

假定任务`P`的输入文件集为`A`，输出文件集为`B`，P在把结果输出到B之前，需要先把lineage信息提交到tachyon里，这些信息描述如何运行`P`来由`A`产生`B`(比如命令行参数、配置信息等)。在这里能够回放(recomputation)的前提是输入数据(文件集`A`)不能变。

从以上流程可以看出，tachyon需要捕获并理解用户提交的任务`P`：tachyon内置了通用了的lineage API(见下表)可以捕获很多流行的分布式并行处理的框架(如mapreduce)，同时也为Spark/Hadoop提供了接口。

| Return | Signature |
| ------ | ------ |
| Global Unique Lineage Id | createDependency(inputFiles, outputFiles, binaryPrograms, executionConfiguration, dependencyType) |
| Dependency Info | getDependency(lineageId) |

`createDependency`中的参数`binaryPrograms`即为上文提到的任务程序`P`，这个程序需要由计算框架来写一个wrapper作为接口，使其既能理解框架里计算代码，也能理解tachyon的行为，tachyon也不会去解析程序的配置信息`executionConfiguration`，在tachyon看来这些配置就是普通的字节数组，具体的解析工作由wrapper来实现。

在实现这一系统时，遇到了两个挑战：
- 如何在长时间运行的系统上限制recomputation的时长(bounding the recomputation cost)
- 如何为recomputation分配资源？(如何在尽量不对其他任务产生影响的情况下尽快的执行recomputation)

### Bounding the recomputation cost（Edge Algorithm）
lineage本质上还是一个基于checkpoint做数据备份与恢复的技术，这里的关键点是何时做checkpoint，针对哪些文件做checkpoint？


### Resource allocation for recomputation


### 系统架构